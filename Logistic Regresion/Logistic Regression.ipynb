{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Q2 First we will focus on a two-class problem. \n",
      "#Use slicing to get a new training and testing set that only contains the instances corresponding to shirt and jeans (remember to also create new label variables!). \n",
      "#Then, train a Logistic Regression classifier, adjusting the C parameter with cross-validation. This time you can chose to use the cross-validation functions provided by sklearn. \n",
      "#Plot the training and validation accuracy as C is incresed, and print the test accuracy for the selected model."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import math\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import LinearSVC, SVC\n",
      "from sklearn.metrics import precision_recall_curve\n",
      "import pylab as pl"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Datos test y train\n",
      "train_data =np.load (\"3dclothing/3dclothing_train.npy\")\n",
      "test_data =np.load (\"3dclothing/3dclothing_test.npy\")\n",
      "#Matriz\n",
      "train_labels = np.array([x.strip() for x in open('3dclothing/3dclothing_labels_train.txt')])\n",
      "test_labels = np.array([x.strip() for x in open('3dclothing/3dclothing_labels_test.txt')])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Datos de test\n",
      "shirt_test=test_data[(test_labels == 'shirt') + (test_labels == 'jeans'),:]\n",
      "shirt_lab_test = test_labels[(test_labels == 'shirt') + (test_labels == 'jeans')]\n",
      "#Datos de lebels\n",
      "shirt_train=train_data[(train_labels == 'shirt') + (train_labels == 'jeans'),:]\n",
      "shirt_lab_train = train_labels[(train_labels == 'shirt') + (train_labels == 'jeans')]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Logistic Regression\n",
      "# Primero creamos un objeto clasificador, con C = 1\n",
      "LogReg = LogisticRegression(C=1)\n",
      "#Luego entrenarlo con los datos de entrenamiento\n",
      "LogReg.fit(shirt_train, shirt_lab_train)\n",
      "# Y, finalmente, utilizar la funci\u00f3n de puntuaci\u00f3n para obtener la precisi\u00f3n\n",
      "print 'Log Reg accuracy', LogReg.score(shirt_test, shirt_lab_test)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Log Reg accuracy 0.831168831169\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Si C = 1 el mejor par\u00e1metro de regularizaci\u00f3n\n",
      "# validaci\u00f3n cruzada de b\u00fasqueda + rejilla\n",
      "# Sklearn:\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "# Definimos el espacio de b\u00fasqueda para el par\u00e1metro Cwe define la busqueda del parametro C\n",
      "parameters = {'C':[10**i for i in range(-7,7)]}\n",
      "# Y crear un objeto de b\u00fasqueda cuadr\u00edcula con el tipo de clasificador\n",
      "# Uso y los par\u00e1metros\n",
      "clf = GridSearchCV(LogisticRegression(), parameters, verbose=False)\n",
      "# Clasificador con rejilla de b\u00fasqueda con el mejor parametro\n",
      "clf.fit(shirt_train, shirt_lab_train)\n",
      "print 'Log Reg with Grid search', clf.score(shirt_test, shirt_lab_test), 'with C =', clf.best_params_['C']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Log Reg with Grid search 0.883116883117 with C = 0.001\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Definicion datos\n",
      "#Let your C search range be from 10^-7 to 10^7.\n",
      "#Hint: use log-scale for the C value in the plot. Hint: \n",
      "#Since we do not have a lot of training data, use 15 folds to ensure the train set will be large enough.\n",
      "\n",
      "D = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
      "A = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
      "P = 0\n",
      "\n",
      "for i in xrange (-7,7):    \n",
      "\tLogReg = LogisticRegression(C=10**i)\n",
      "\tD[P]=i\n",
      "\tLogReg.fit(train_data, train_labels)\n",
      "\tA[P] = LogReg.score(test_data, test_labels)\n",
      "\tprint 'Log Reg accuracy', A[P]\n",
      "\tP+=1\n",
      "#Plot\n",
      "pl.plot(D[:14],A[:14])\n",
      "\n",
      "pl.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Log Reg accuracy 0.251207729469\n",
        "Log Reg accuracy 0.429951690821\n",
        "Log Reg accuracy"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.521739130435\n",
        "Log Reg accuracy"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.613526570048\n",
        "Log Reg accuracy"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.676328502415\n",
        "Log Reg accuracy"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.623188405797\n",
        "Log Reg accuracy"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.613526570048\n",
        "Log Reg accuracy"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.579710144928\n",
        "Log Reg accuracy"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.570048309179\n",
        "Log Reg accuracy"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.599033816425\n",
        "Log Reg accuracy"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.599033816425\n",
        "Log Reg accuracy"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.584541062802\n",
        "Log Reg accuracy"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.584541062802\n",
        "Log Reg accuracy"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.56038647343\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Q3 Now, train a multi-class Logistic Regression classifier with the complete training set. \n",
      "#Again, plot the training and validation accuracy as C increases, and print the final test accuracy. \n",
      "\n",
      "D = [1,2,3,4,5,6]\n",
      "A = [1,2,3,4,5,6]\n",
      "P = 0\n",
      "\n",
      "for i in xrange (-3,3):    \n",
      "\tLogReg = LogisticRegression(C=10**i)\n",
      "\tD[P]=i\n",
      "\tLogReg.fit(train_data, train_labels)\n",
      "\tA[P] = LogReg.score(test_data, test_labels)\n",
      "\tprint 'Log Reg accuracy', A[P]\n",
      "\tP+=1\n",
      "#Plot\n",
      "pl.plot(D[:5],A[:5])\n",
      "\n",
      "pl.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Log Reg accuracy 0.676328502415\n",
        "Log Reg accuracy"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.623188405797\n",
        "Log Reg accuracy"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.613526570048\n",
        "Log Reg accuracy"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.579710144928\n",
        "Log Reg accuracy"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.570048309179\n",
        "Log Reg accuracy"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.599033816425\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Q4 Sometimes we want to re-use a trained classified in another system, or with another programming language. \n",
      "# Other times we just want to save it to disk for later usage. \n",
      "# Given a trained linear classifier object, explain what information should we be saving in order to be able to do so. \n",
      "# Next, inspect the \"shirts vs jeans\" logistic regression classifier object we have trained in Question 2 \n",
      "# (re-train it if necessary) and identify which variables contain said information. \n",
      "# Finally, write the code necessary to use these variables to classify new test samples. \n",
      "\n",
      "#Datos test y train\n",
      "#train_data =np.load (\"3dclothing/3dclothing_train.npy\")\n",
      "#test_data =np.load (\"3dclothing/3dclothing_test.npy\")\n",
      "#Matriz\n",
      "#train_labels = np.array([x.strip() for x in open('3dclothing/3dclothing_labels_train.txt')])\n",
      "#test_labels = np.array([x.strip() for x in open('3dclothing/3dclothing_labels_test.txt')])\n",
      "\n",
      "filter_scores = test_data > 0.5\n",
      "\n",
      "true_positive = float(sum(filter_scores & test_labels))\n",
      "false_positive = float(sum(filter_scores & -test_labels))\n",
      "false_negative = float(sum(-filter_scores & test_labels))\n",
      "true_negative = float(sum(-filter_scores & -test_labels))\n",
      "\n",
      "#F1-score\n",
      "#F1-beta\n",
      "\n",
      "precision = true_positive/(true_positive+false_positive)\n",
      "recall = true_positive/(true_positive+false_negative)\n",
      "F1_score = 2*((precision*recall)/(precision+recall))\n",
      "\n",
      "beta = 0.5\n",
      "f_beta = (1+beta**2)*((precision*recall)/(beta**2*precision+recall))\n",
      "\n",
      "print 'F1-score is', F1_score\n",
      "print 'F-beta score is', f_beta"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "unsupported operand type(s) for &: 'numpy.ndarray' and 'numpy.ndarray'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-7-0179ea38ada4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mfilter_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mtrue_positive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter_scores\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mfalse_positive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter_scores\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mfalse_negative\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mfilter_scores\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for &: 'numpy.ndarray' and 'numpy.ndarray'"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Q6 We will now compare the performance of the linear and the RBF Support Vector Machines in a real dataset: \n",
      "#Train the two classifiers in the jeans vs shirts problem from Q2, and compute the accuracy on the test set. \n",
      "#What happened? "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#accuracy RBF SVM\n",
      "for i in xrange (-7,7):    \n",
      "\tLogReg = LogisticRegression(C=10**i)\n",
      "\tLogReg.fit(shirt_train, shirt_lab_train)\n",
      "\tA = LogReg.score(shirt_test, shirt_lab_test)\n",
      "\tprint 'Log Reg accuracy', A\n",
      "\tclf = SVC(C=10**i)\n",
      "\tclf.fit(train_data, train_labels)\n",
      "print 'RBF SVM accuracy', clf.score(test_data, test_labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}