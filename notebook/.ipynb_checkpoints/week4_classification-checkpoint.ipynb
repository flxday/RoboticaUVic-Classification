{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# \u00a1Bienvenido! En este cuaderno vamos a ver c\u00f3mo utilizar sklearn para llevar a cabo la clasificaci\u00f3n\n",
      "# Primero vamos a importar las librer\u00edas necesarias:\n",
      "import numpy as np\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import LinearSVC, SVC\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "# Sklearn se divide en varios sub-bibliotecas para la funcionalidad diferente, por\n",
      "# Ver una descripci\u00f3n completa de la API aqu\u00ed: http://scikit-learn.org/stable/modules/classes.html"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# A continuaci\u00f3n vamos a cargar algunos datos con los que jugar. En este cuaderno vamos a utilizar\n",
      "# El conjunto de datos del olmo del repositorio UCI. El conjunto de datos se debe poner\n",
      "# En la misma carpeta que el bloc de notas. \n",
      "\n",
      "# Con este diccionario vamos a codificar la funci\u00f3n categ\u00f3rica \"g\u00e9nero\".\n",
      "cat_gender = {'I':np.array([1,0,0]), 'M':np.array([0,1,0]), 'F':np.array([0,0,1])}\n",
      "# Cargar los datos y el masaje a ser utilizable\n",
      "abalone_data = [x.strip().split(',') for x in open('abalone.data').readlines()] \n",
      "# Construir una matriz con la funci\u00f3n categ\u00f3rica (primera) y las restantes caracter\u00edsticas\n",
      "abalone_data = np.array([np.hstack((cat_gender[x[0]],np.array(map(float,x[1:])))) for x in abalone_data])\n",
      "# Tome la \u00faltima columna como etiqueta\n",
      "abalone_labels = abalone_data[:,-1].astype('int')\n",
      "# Las columnas restantes son los datos\n",
      "abalone_data = abalone_data[:,:-1]\n",
      "# Dividimos los datos de forma aleatoria entre un tren y prueba\n",
      "naba= abalone_labels.shape[0]\n",
      "sel = range(naba)\n",
      "np.random.seed(25)\n",
      "np.random.shuffle(sel)\n",
      "aba_train_data = abalone_data[sel[:naba/2],:]\n",
      "aba_train_labs = abalone_labels[sel[:naba/2]]\n",
      "aba_test_data = abalone_data[sel[naba/2:],:]\n",
      "aba_test_labs = abalone_labels[sel[naba/2:]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# K-NN\n",
      "# Definimos una funci\u00f3n para ejecutar el clasificador K-NN con una gama de valores \"K '\n",
      "def runknn(tr_data, tr_labels, te_data, te_labels):\n",
      "    for k in range(1,15,2):\n",
      "        # Aqu\u00ed se utiliza la funci\u00f3n de KNN scikit aprender (en el\n",
      "        # Tareas que tendr\u00e1 que poner en pr\u00e1ctica ustedes mismos)\n",
      "        # En primer lugar, crear un objeto clasificador\n",
      "        knn = KNeighborsClassifier(k)\n",
      "    # A continuaci\u00f3n, nos \"entrenar\" con los datos de entrenamiento\n",
      "        knn.fit(aba_train_data, aba_train_labs)\n",
      "        # Finalmente calculamos la exactitud de los datos de pruebaa\n",
      "        acc = knn.score(aba_test_data, aba_test_labs)\n",
      "        print 'Accuracy (k=%d): %.4f'%(k,acc)\n",
      "# Llamamos a la funci\u00f3n con las divisiones de tren y de prueba\n",
      "runknn(aba_train_data, aba_train_labs, aba_test_data, aba_test_labs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy (k=1): 0.2030\n",
        "Accuracy (k=3): 0.2121\n",
        "Accuracy (k=5): 0.2437"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Accuracy (k=7): 0.2623\n",
        "Accuracy (k=9): 0.2623"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Accuracy (k=11): 0.2657\n",
        "Accuracy (k=13): 0.2666"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Logistic Regression\n",
      "# Del mismo modo que en el KNN, primero creamos un objeto clasificador, con C = 1\n",
      "LogReg = LogisticRegression(C=1)\n",
      "#Luego entrenarlo con los datos de entrenamiento\n",
      "LogReg.fit(aba_train_data, aba_train_labs)\n",
      "# Y, finalmente, utilizar la funci\u00f3n de puntuaci\u00f3n para obtener la precisi\u00f3n\n",
      "print 'Log Reg accuracy', LogReg.score(aba_test_data, aba_test_labs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# But, is C=1 the best regularization parameter? We will\n",
      "# find out with cross-validation + grid search\n",
      "# sklearn has a handy function for that too:\n",
      "\n",
      "# Sin embargo, es C = 1 el mejor par\u00e1metro de regularizaci\u00f3n? Lo haremos\n",
      "# Averiguar con la validaci\u00f3n cruzada de b\u00fasqueda + rejilla\n",
      "# Sklearn tiene una funci\u00f3n muy \u00fatil para eso tambi\u00e9n:\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "# Definimos el espacio de b\u00fasqueda para el par\u00e1metro Cwe define the search space for the C parameter\n",
      "parameters = {'C':[10**i for i in range(-7,7)]}\n",
      "# Y crear un objeto de b\u00fasqueda cuadr\u00edcula con el tipo de clasificador queremos\n",
      "# Uso y los par\u00e1metros\n",
      "clf = GridSearchCV(LogisticRegression(), parameters, verbose=False)\n",
      "# Y entrenamos el clasificador con rejilla de b\u00fasqueda (esto va a utilizar la validaci\u00f3n cruzada\n",
      "# Para seleccionar el mejor par\u00e1metro)\n",
      "clf.fit(aba_train_data, aba_train_labs)\n",
      "print 'Log Reg with Grid search', clf.score(aba_test_data, aba_test_labs), 'with C =', clf.best_params_['C']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Linear Support Vector Machine\n",
      "# The interface for the different classifiers is very similar; the Linear SVM\n",
      "# works in the same way as the logistic regression\n",
      "clf = LinearSVC(C=1)\n",
      "clf.fit(aba_train_data, aba_train_labs)\n",
      "print 'Linear SVM score', clf.score(aba_test_data, aba_test_labs)\n",
      "parameters = {'C':[10**i for i in range(-3, 4)]}\n",
      "clf = GridSearchCV(LinearSVC(), parameters, verbose=False)\n",
      "clf.fit(aba_train_data, aba_train_labs)\n",
      "print 'Linear SVM score with Grid Search', clf.score(aba_test_data, aba_test_labs), 'with C =', clf.best_params_['C']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Now we will do the same with the kernelized SVM\n",
      "clf = SVC(C=1)\n",
      "clf.fit(aba_train_data, aba_train_labs)\n",
      "print 'RBF SVM score', clf.score(aba_test_data, aba_test_labs)\n",
      "# We can actually define several parameters we want to optimize over:\n",
      "parameters = {'C':[10**i for i in range(-3, 4)], 'kernel':['linear', 'rbf']}\n",
      "clf = GridSearchCV(SVC(), parameters, verbose=False)\n",
      "clf.fit(aba_train_data, aba_train_labs)\n",
      "print 'RBF SVM score with Grid Search', clf.score(aba_test_data, aba_test_labs), 'with C =', \\\n",
      "    parameters.best_params_['C'], 'and kernel =', parameters.best_params_['kernel']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}